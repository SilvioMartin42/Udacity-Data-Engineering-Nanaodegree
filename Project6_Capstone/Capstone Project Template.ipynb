{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "### IMPORTANT: HOW TO RUN \n",
    "\n",
    "* Please download the temperature data from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) \n",
    "* De-compress it and load it to the Workspace \n",
    "* Run the Capstone Jupyter Notebook\n",
    "\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to use several data sources to create a star schema like data model for analytical purposes such as finding out \n",
    "\n",
    "* from where\n",
    "* to where\n",
    "* at what age\n",
    "* with which educational background\n",
    "\n",
    "immigrants come to the United States in April 2016.\n",
    "\n",
    "Additionally, the data can be used for creating correlation models e.g. to find out, if the immigrant's home country's temperature  has an influence on the state the immigrant migrates to.\n",
    "\n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Start SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. \n",
    "\n",
    "The projects overall goal is to create fact and dimension data sets in star schema form for analyzing immigration data from April 2016 to create a prototype that, if accepted by the use case owners, can later be scaled-up.\n",
    "\n",
    "* **What data do you use?** US Immigration, airport key data, U.S. city demographics data, temperature data\n",
    "* **What is your end solution look like?** Star schema with immigration fact table and dimension tables regarding airports, U.S. city demographics and average temperatures per city\n",
    "* **What tools did you use?** Python pandas, Spark Data Frame functions\n",
    "\n",
    "#### Describe, Gather and Explore Data \n",
    "Describe the data sets you're using. \n",
    "\n",
    "* **Where did it come from?** See data set descriptions below\n",
    "* **What type of information is included?** See 4.3 Data Dictionnary for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**I94_Immigration data:** \n",
    "Originally coming from the [US National Tourism and Trade Office](https://www.trade.gov/national-travel-and-tourism-office)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1000 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_df = pd.read_csv(\"immigration_data_sample.csv\")\n",
    "print(f\"The dataset has {len(immi_df)} entries.\")\n",
    "immi_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Have a look at entire immigration data from April 2016 using spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immi_big_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_big_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_big_df.cache()\n",
    "immi_big_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Airport data:** Originally from [Datahub.io](https://datahub.io/core/airport-codes#data)\n",
    "\n",
    "\n",
    "Have a look at data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 55075 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df = pd.read_csv(\"airport-codes_csv.csv\")\n",
    "print(f\"The dataset has {len(airport_df)} entries.\")\n",
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Load dataset in Spark for further work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df = spark.read.format('csv').option('delimiter',',').option('header','true').load(\"airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Port keys are extracted from SAS-file using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_valid_ports():\n",
    "    \"\"\"\n",
    "    Use the i94 labels SAS file to create valid port labels\n",
    "    \"\"\"\n",
    "    # Create list of valid ports\n",
    "    with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "        lines = f.readlines()\n",
    "    ports = []\n",
    "    for line in lines[302:962]:\n",
    "        ports.append(line.strip())\n",
    "    ports_split = []    \n",
    "    for port in ports:\n",
    "        ports_split.append(port.split(\"=\"))\n",
    "    port_codes = []\n",
    "    for code in ports_split:\n",
    "        port_codes.append(code[0].replace(\"'\",\"\").strip())\n",
    "    port_locations = []\n",
    "    for location in ports_split:\n",
    "        port_locations.append(location[1].replace(\"'\",\"\").strip())\n",
    "    port_cities = []\n",
    "    for city in port_locations:\n",
    "        port_cities.append(city.split(\",\")[0])\n",
    "    port_states = []\n",
    "    for state in port_locations:\n",
    "        port_states.append(state.split(\",\")[-1])\n",
    "\n",
    "    port_location_df = pd.DataFrame({\"port_code\" : port_codes, \"port_city\": port_cities, \"port_state\": port_states})\n",
    "\n",
    "    return port_location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 660 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>port_city</th>\n",
       "      <th>port_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTH</td>\n",
       "      <td>DUTCH HARBOR</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EGL</td>\n",
       "      <td>EAGLE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRB</td>\n",
       "      <td>FAIRBANKS</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOM</td>\n",
       "      <td>HOMER</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HYD</td>\n",
       "      <td>HYDER</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port_code                 port_city port_state\n",
       "0       ALC                     ALCAN         AK\n",
       "1       ANC                 ANCHORAGE         AK\n",
       "2       BAR  BAKER AAF - BAKER ISLAND         AK\n",
       "3       DAC             DALTONS CACHE         AK\n",
       "4       PIZ    DEW STATION PT LAY DEW         AK\n",
       "5       DTH              DUTCH HARBOR         AK\n",
       "6       EGL                     EAGLE         AK\n",
       "7       FRB                 FAIRBANKS         AK\n",
       "8       HOM                     HOMER         AK\n",
       "9       HYD                     HYDER         AK"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_location_df = create_valid_ports()\n",
    "print(f\"The dataset has {len(port_location_df)} entries.\")\n",
    "port_location_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**U.S. City demographics data:** Originally from [Opensoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 2891 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"us-cities-demographics.csv\", delimiter=\";\")\n",
    "print(f\"The dataset has {len(cities_df)} entries.\")\n",
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Load data in Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cities_df = spark.read.format('csv').option('delimiter',';').option('header', 'true').load(\"us-cities-demographics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**World Temperature Data since 1750:**\n",
    "Originally from [Kaggle](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1480204 entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.read_csv(\"GlobalLandTemperaturesByCity.csv\")\n",
    "print(f\"The dataset has {len(temp_df)} entries.\")\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Load data in Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = spark.read.format('csv').option('delimiter',',').option('header','true').load(\"GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In this fictional case, the departments that will be using the data model later on demanded that there should be no missing values in the sets. Therefore, cleaning the data sets using `.dropna` is obligatory. For this reason, a function to drop all rows with NA entries from a given table is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_table(df, subset=None):\n",
    "    \"\"\"\n",
    "    Drop empty rows in dataframe\n",
    "    \"\"\"\n",
    "    print(f\"number of rows in table before removing empty rows: {df.count()}\")    \n",
    "    clean_df = df.dropna(subset=subset)\n",
    "    print(f\"number of rows in table after removing empty rows: {clean_df.count()}\")\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Explore and clean immigration data \n",
    "\n",
    "The following impressions can be won from the \"immigration_data_sample.csv\" file:\n",
    "* the imported data only contains data points from April 2016, as needed\n",
    "* the columns \"insnum\", \"entdepu\", \"occup\", \"visapost\" contain mostly NA entries or are not needed for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|summary| i94mon|\n",
      "+-------+-------+\n",
      "|  count|3096313|\n",
      "|   mean|    4.0|\n",
      "| stddev|    0.0|\n",
      "|    min|    4.0|\n",
      "|    max|    4.0|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_big_df.describe(\"i94mon\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|               i94yr|\n",
      "+-------+--------------------+\n",
      "|  count|             3096313|\n",
      "|   mean|              2016.0|\n",
      "| stddev|4.282829613261096...|\n",
      "|    min|              2016.0|\n",
      "|    max|              2016.0|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_big_df.describe(\"i94yr\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+-----------------+--------+\n",
      "|summary|           insnum|entdepu|            occup|visapost|\n",
      "+-------+-----------------+-------+-----------------+--------+\n",
      "|  count|           113708|    392|             8126| 1215063|\n",
      "|   mean|4131.050016327899|   null|          885.675|   999.0|\n",
      "| stddev|8821.743471773656|   null|264.6551105950961|     0.0|\n",
      "|    min|                0|      U|              049|     999|\n",
      "|    max|           YM0167|      Y|              WTR|     ZZZ|\n",
      "+-------+-----------------+-------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_big_df.describe([\"insnum\", \"entdepu\", \"occup\", \"visapost\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Cleaning Immigration data: \n",
    "\n",
    "* take out data from airports that have the same name in city and state, as the data might be corrupted\n",
    "* drop columns with mostly NA values, as they are not needed for the analysis\n",
    "* drop all entries with NA entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in immigration dataset before cleaning invalid ports: 3096313\n",
      "number of rows in immigration dataset after cleaning invalid ports: 2995590\n"
     ]
    }
   ],
   "source": [
    "#take out data from ports that have same name in city and state\n",
    "invalid_ports = list(set(port_location_df[port_location_df[\"port_city\"] == port_location_df[\"port_state\"]][\"port_code\"].values))\n",
    "\n",
    "print(f\"number of rows in immigration dataset before cleaning invalid ports: {immi_big_df.count()}\")\n",
    "filtered_immi_df = immi_big_df[~immi_big_df[\"i94port\"].isin(invalid_ports)]\n",
    "print(f\"number of rows in immigration dataset after cleaning invalid ports: {filtered_immi_df.count()}\")\n",
    "# \"~\" is \"not\"\n",
    "\n",
    "# Drop columns with mostly NA entries\n",
    "dropped_columns = (\"insnum\", \"entdepu\", \"occup\", \"visapost\")\n",
    "dropped_immi_df = filtered_immi_df.drop(*dropped_columns)\n",
    "\n",
    "# Drop all NA entries in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in table before removing empty rows: 2995590\n",
      "number of rows in table after removing empty rows: 2306750\n"
     ]
    }
   ],
   "source": [
    "immi_df_cleaned = clean_table(dropped_immi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Immigration data is cleaned for transferring data into data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Explore and clean Airport data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Have a look at entries with continent is \"NA\", as these ports might not be interesting for immigration, as they are too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "| 00AS|small_airport|      Fulton Airport|        1100|       NA|         US|     US-OK|        Alex|    00AS|     null|      00AS|-97.8180194, 34.9...|\n",
      "| 00AZ|small_airport|      Cordes Airport|        3810|       NA|         US|     US-AZ|      Cordes|    00AZ|     null|      00AZ|-112.165000915527...|\n",
      "| 00CA|small_airport|Goldstone /Gts/ A...|        3038|       NA|         US|     US-CA|     Barstow|    00CA|     null|      00CA|-116.888000488, 3...|\n",
      "| 00CL|small_airport| Williams Ag Airport|          87|       NA|         US|     US-CA|       Biggs|    00CL|     null|      00CL|-121.763427, 39.4...|\n",
      "| 00CN|     heliport|Kitchen Creek Hel...|        3350|       NA|         US|     US-CA| Pine Valley|    00CN|     null|      00CN|-116.4597417, 32....|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|summary|continent|\n",
      "+-------+---------+\n",
      "|  count|    55075|\n",
      "|   mean|     null|\n",
      "| stddev|     null|\n",
      "|    min|       AF|\n",
      "|    max|       SA|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.describe(\"continent\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "How often does each class occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|continent|count|\n",
      "+---------+-----+\n",
      "|       NA|27719|\n",
      "|       SA| 7709|\n",
      "|       AS| 5350|\n",
      "|       AN|   28|\n",
      "|       OC| 3067|\n",
      "|       EU| 7840|\n",
      "|       AF| 3362|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.select(\"continent\").groupby(\"continent\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It seems like most entries are NA. Let's find out, what types and names these have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27719 airports with NA as continent. Their types are the following:\n",
      "+--------------+-----+\n",
      "|          type|count|\n",
      "+--------------+-----+\n",
      "|   balloonport|   19|\n",
      "|        closed| 2072|\n",
      "|      heliport| 7035|\n",
      "| large_airport|  209|\n",
      "|medium_airport| 1247|\n",
      "| seaplane_base|  956|\n",
      "| small_airport|16181|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {airport_df.select(['type', 'name']).where(airport_df.continent == 'NA').count()} airports with NA as continent. Their types are the following:\")\n",
    "airport_df.select(['type', 'name']).where(airport_df.continent == 'NA').groupby('type').count().orderBy('type').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As most Ariports with 'NA' as continent seem too small to be international airports for immigration, we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df_cleaned = airport_df.filter(airport_df.continent != 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total 55075 airports, 27356 with continents other than NA\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are in total {airport_df_cleaned.count() + airport_df.select(['type', 'name']).where(airport_df.continent == 'NA').count()} \\\n",
    "airports, {airport_df_cleaned.count()} with continents other than NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now, we need to delete all other entries with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in table before removing empty rows: 55075\n",
      "number of rows in table after removing empty rows: 2746\n"
     ]
    }
   ],
   "source": [
    "airport_df_cleaned_final = clean_table(airport_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After cleaning the airport table, there are 198 large airports remaining that can be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          type|count|\n",
      "+--------------+-----+\n",
      "| large_airport|  198|\n",
      "| seaplane_base|   54|\n",
      "|      heliport|   19|\n",
      "|        closed|   24|\n",
      "|medium_airport|  876|\n",
      "| small_airport| 1575|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df_cleaned_final.groupby('type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.3 Explore and clean U.S. City Demographics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The cities data has just a small amount of missing values. Additionally, the `port key` data set is used to add the necessary airport to every city as the data sets primary key where it is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|summary|City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race|Count|\n",
      "+-------+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|  count|2891| 2891|      2891|           2888|             2888|            2891|              2878|        2878|                  2875|      2891|2891| 2891|\n",
      "+-------+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df.summary('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Functions used for adding airports to cities using function `create_valid_ports()` defined in the beginning of the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf()\n",
    "def get_port(city):\n",
    "    \"\"\"\n",
    "    Add valid port based on city data\n",
    "    \n",
    "    Key Arguments:\n",
    "    city -- column from a data frame containing names of cities\n",
    "    \"\"\"\n",
    "    port_location_df = create_valid_ports()\n",
    "    for port_city in port_location_df.port_city:\n",
    "        if city.lower() in port_city.lower():\n",
    "            return port_location_df[port_location_df[\"port_city\"]==port_city][\"port_code\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_port(df):\n",
    "    \"\"\"\n",
    "    Add valid ports to table to allow joining of tables\n",
    "    \n",
    "    Key Arguments:\n",
    "    df -- dataframe containing at least a column called 'City' containing city names \n",
    "    \"\"\"\n",
    "    port_location_df = create_valid_ports()\n",
    "    df = df.withColumn(\"i94port\", get_port(df.City))\n",
    "    new_df = df.filter(df.i94port != 'null')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in table before removing empty rows: 879\n",
      "number of rows in table after removing empty rows: 875\n"
     ]
    }
   ],
   "source": [
    "#clean demographics data set and add ports as primary key\n",
    "cities_df = add_port(cities_df)\n",
    "cities_df = clean_table(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change columns names for better usability\n",
    "cities_df_final = cities_df.withColumnRenamed('Median Age','median_age') \\\n",
    "                                                        .withColumnRenamed('Male Population', 'male_population') \\\n",
    "                                                        .withColumnRenamed('Female Population', 'female_population') \\\n",
    "                                                        .withColumnRenamed('Total Population', 'total_population') \\\n",
    "                                                        .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "                                                        .withColumnRenamed('Foreign-born', 'foreign_born') \\\n",
    "                                                        .withColumnRenamed('Average Household Size', 'average_household_size') \\\n",
    "                                                        .withColumnRenamed('State Code', 'state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+-------+\n",
      "|        City|       State|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|                Race| Count|i94port|\n",
      "+------------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+-------+\n",
      "|      Newark|  New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White| 76402|    NEW|\n",
      "|      Peoria|    Illinois|      33.1|          56229|            62432|          118661|              6634|        7517|                   2.4|        IL|American Indian a...|  1343|    PIA|\n",
      "|Philadelphia|Pennsylvania|      34.1|         741270|           826172|         1567442|             61995|      205339|                  2.61|        PA|               Asian|122721|    PHI|\n",
      "|  Fort Myers|     Florida|      37.3|          36850|            37165|           74015|              4312|       15365|                  2.45|        FL|               White| 50169|    FMY|\n",
      "|      Laredo|       Texas|      28.8|         124305|           131484|          255789|              4921|       68427|                  3.66|        TX|American Indian a...|  1253|    LCB|\n",
      "+------------+------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df_final.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "U.S. City Demographics Data is now cleaned and ready for model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.4 Explore and clean Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+---------+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|     City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+---------+-------+--------+---------+\n",
      "|2013-09-01|              null|                         null| A Coruña|  Spain|  42.59N|    8.73W|\n",
      "|2013-09-01|              null|                         null|Abakaliki|Nigeria|   5.63N|    8.07E|\n",
      "|2013-09-01|              null|                         null|   Aachen|Germany|  50.63N|    6.34E|\n",
      "|2013-09-01|              null|                         null|    Çorlu| Turkey|  40.99N|   27.69E|\n",
      "|2013-09-01|              null|                         null|  Aalborg|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+---------+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.orderBy('dt', ascending=False).show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   max(dt)|\n",
      "+----------+\n",
      "|2013-09-01|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.select(max(col('dt'))).show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data set only contains data until 2013, so we can only use average temperatures from 2013 for a regression model that compares city temperatures. \n",
    "\n",
    "If the prototype should be scaled, the temperature data should be more up-to-date. The 2013 data is enough, though, to create a proof of concept.\n",
    "\n",
    "Cleaning involves:\n",
    "\n",
    "* filtering for entries from 2013 or newer\n",
    "* only using entries that are not `null`\n",
    "* adding ports using the `add_port()` function defined beforehand\n",
    "* using the `clean_table()` function to get rid of remaining entries that are `null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in table before removing empty rows: 364\n",
      "number of rows in table after removing empty rows: 364\n"
     ]
    }
   ],
   "source": [
    "temp_df_cleaned = temp_df.filter(temp_df.dt >= '2013-01-01')\n",
    "temp_df_cleaned = temp_df_cleaned.filter(temp_df_cleaned.AverageTemperature != 'null')\n",
    "temp_df_cleaned = add_port(temp_df_cleaned)\n",
    "temp_df_cleaned_final = clean_table(temp_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+--------+--------------+--------+---------+-------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|    City|       Country|Latitude|Longitude|i94port|\n",
      "+----------+------------------+-----------------------------+--------+--------------+--------+---------+-------+\n",
      "|2013-01-01|5.1930000000000005|           0.7040000000000001|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|2013-02-01|4.1160000000000005|                        0.614|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|2013-03-01|             2.786|                         0.43|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|2013-04-01|             5.374|                        0.718|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "|2013-05-01|             8.238|           0.5870000000000001|Aberdeen|United Kingdom|  57.05N|    1.48W|    ABE|\n",
      "+----------+------------------+-----------------------------+--------+--------------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df_cleaned_final.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_cleaned_final.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model:\n",
    "\n",
    "The data model consists of an `Immigration` fact table and three dimension tables: `Temperature`, `Demographics` and `Airport`. The Tables `Temperature` and `Demographics` can be connected to the fact table using the `i94port` key, which allows the creation of regression models using temperatures or locations where immigrants come from or go to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| table | columns | description | type |\n",
    "|---|---|---|---|\n",
    "| Immigrations | cicid; i94yr; i94mon; i94cit; i94res; i94port; arrdate; i94mode; i94addr; depdate; i94bir; i94visa; count; dtadfile; entdepa; entdepd; matflag; biryear; dtaddto; gender; airline; admnum; fltno; visatype;  | Contains i94 immigration data | Fact Table |\n",
    "| Temperature | dt; AverageTemperature; AverageTemperatureUncertainty;  City; Country; Latitude; Longitude; i94port; | Contains temperature data | Dimension Table |\n",
    "| Demographics | City; State; Median Age; Male Population; Female Population; Total Population; Number of Veterans; Foreign-born; Average Household Size; State Code; Race; Count; i94port; | Contains city demographics data  | Dimension Table |\n",
    "| Airport | ident; type; name; elevation_ft; continent; iso_country; iso_region;  municipality; gps_code; iata_code; local_code; coordinates; | Contains airport data | Dimension Table |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Clean provided data sets \n",
    "2. Create fact table\n",
    "3. Create dimention tables\n",
    "4. Run Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "To build the data model, several functions have to be defined to create the final tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.1 Create fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_immigration_data(immi_df):\n",
    "    \"\"\"\n",
    "    Write immigration data to parquet\n",
    "    \"\"\"\n",
    "    immigration_table = immi_df.select([\"cicid\" ,\"i94yr\" ,\"i94mon\" ,\"i94cit\" ,\"i94res\" ,\"i94port\" ,\"arrdate\" \\\n",
    "                                               ,\"i94mode\" ,\"i94addr\" ,\"depdate\" ,\"i94bir\" ,\"i94visa\" ,\"count\" ,\"dtadfile\" \\\n",
    "                                               ,\"entdepa\" ,\"entdepd\" ,\"matflag\" ,\"biryear\" ,\"dtaddto\" ,\"gender\" ,\"airline\" \\\n",
    "                                               ,\"admnum\" ,\"fltno\" ,\"visatype\"])\n",
    "    immigration_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"./output/immigration_table.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.2 Create the dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "def write_temperature_data(temp_df_cleaned_final):\n",
    "    \"\"\"\n",
    "    Write temperature data to parquet\n",
    "    \"\"\"\n",
    "    temperature_table = temp_df_cleaned_final.select([\"dt\" ,\"AverageTemperature\" ,\"AverageTemperatureUncertainty\" ,\"City\" \\\n",
    "                                                       ,\"Country\" ,\"Latitude\" ,\"Longitude\",\"i94port\"])\n",
    "    temperature_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"./output/temperature_table.parquet\")\n",
    "    \n",
    "def write_demographics_data(cities_df_final):\n",
    "    \"\"\"\n",
    "    Write demographics data to parquet\n",
    "    \"\"\"\n",
    "    demographics_table = cities_df_final.select([\"City\" ,\"State\" ,\"median_age\" ,\"male_population\" \\\n",
    "                                                               ,\"female_population\" ,\"total_population\" \\\n",
    "                                                               ,\"number_of_veterans\" ,\"foreign_born\" \\\n",
    "                                                               ,\"average_household_size\" ,\"state_code\" ,\"Race\" ,\"Count\",\"i94port\"])\n",
    "    demographics_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"./output/demographics_table.parquet\")\n",
    "    \n",
    "def write_airport_code_data(airport_df_cleaned_final):\n",
    "    \"\"\"\n",
    "    Write demographics data to parquet\n",
    "    \"\"\"\n",
    "    airport_code_table = airport_df_cleaned_final.select([\"ident\" ,\"type\" ,\"name\" ,\"elevation_ft\" ,\"continent\" ,\"iso_country\" ,\"iso_region\" ,\"municipality\" ,\"gps_code\" ,\"iata_code\" ,\"local_code\" ,\"coordinates\"])\n",
    "    airport_code_table.write.mode(\"append\").partitionBy(\"iata_code\").parquet(\"./output/airport_code_table.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create all tables as `parquet` files to create entire model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%rm -rf ./output/\n",
    "write_immigration_data(immi_df_cleaned)\n",
    "write_temperature_data(temp_df_cleaned_final)\n",
    "write_demographics_data(cities_df_final)\n",
    "write_airport_code_data(airport_df_cleaned_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now, all fact and dimension tables are available as parquet-files and can be read for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Two quality checks will be included:\n",
    "\n",
    "* check if table exists\n",
    "* check if table is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Define functions for quality checks and a function to run all checks on a data table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def table_exists(df):\n",
    "    \"\"\"\n",
    "    Checks if the dataframe that was entered exists\n",
    "    \"\"\"\n",
    "    return df is not None\n",
    "\n",
    "# Check if table is empty\n",
    "def table_empty(df):\n",
    "    \"\"\"\n",
    "    Checks if the dataframe that was entered contains any rows\n",
    "    \"\"\"\n",
    "    return df.count() != 0\n",
    "\n",
    "def data_quality_check(df):\n",
    "    \"\"\"\n",
    "    Checks if the dataframe entered exists and contains any data \n",
    "    \"\"\"\n",
    "    if table_exists(df):\n",
    "        print(\"Data quality check #1 passed, table exists\\n\")\n",
    "    else:\n",
    "        print(\"Data quality check #1 failed, table is missing\\n\")\n",
    "    if table_empty(df):\n",
    "        print(\"Data quality check #2 passed, table not empty\\n\")\n",
    "    else:\n",
    "        print(\"Data quality check #2 failed, table is empty\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run Data Quality Checks for every table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immigration table check\n",
      "Data quality check #1 passed, table exists\n",
      "\n",
      "Data quality check #2 passed, table not empty\n",
      "\n",
      "Temperature table check\n",
      "Data quality check #1 passed, table exists\n",
      "\n",
      "Data quality check #2 passed, table not empty\n",
      "\n",
      "U.S. City Demographics table check\n",
      "Data quality check #1 passed, table exists\n",
      "\n",
      "Data quality check #2 passed, table not empty\n",
      "\n",
      "Airport table check\n",
      "Data quality check #1 passed, table exists\n",
      "\n",
      "Data quality check #2 passed, table not empty\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Immigration table check\")\n",
    "data_quality_check(immi_df_cleaned)\n",
    "\n",
    "print(\"Temperature table check\")\n",
    "data_quality_check(temp_df_cleaned_final)\n",
    "\n",
    "print(\"U.S. City Demographics table check\")\n",
    "data_quality_check(cities_df_final)\n",
    "\n",
    "print(\"Airport table check\")\n",
    "data_quality_check(airport_df_cleaned_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Read data tables from parquet files to use them for example query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read parquet files\n",
    "parI94 = spark.read.parquet(\"./output/immigration_table.parquet\")\n",
    "parTemp= spark.read.parquet(\"./output/temperature_table.parquet\")\n",
    "parDem = spark.read.parquet(\"./output/demographics_table.parquet\")\n",
    "parAir = spark.read.parquet(\"./output/airport_code_table.parquet\")\n",
    "\n",
    "parI94.createOrReplaceTempView(\"immigration\")\n",
    "parTemp.createOrReplaceTempView(\"temperature\")\n",
    "parDem.createOrReplaceTempView(\"demographics\")\n",
    "parAir.createOrReplaceTempView(\"airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+------+-------+-----+--------+-------+-------+-------+-------+--------+------+-------+---------------+-----+--------+-------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|entdepa|entdepd|matflag|biryear| dtaddto|gender|airline|         admnum|fltno|visatype|i94port|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+------+-------+-----+--------+-------+-------+-------+-------+--------+------+-------+---------------+-----+--------+-------+\n",
      "|5750212.0|2016.0|   4.0| 254.0| 209.0|20574.0|    1.0|     GU|20576.0|  62.0|    2.0|  1.0|20160430|      G|      O|      M| 1954.0|07282016|     M|     UA|5.9504946533E10|00150|      WT|    AGA|\n",
      "|5750213.0|2016.0|   4.0| 254.0| 209.0|20574.0|    1.0|     GU|20576.0|  44.0|    2.0|  1.0|20160430|      G|      O|      M| 1972.0|07282016|     F|     UA|5.9504949233E10|00150|      WT|    AGA|\n",
      "|5750214.0|2016.0|   4.0| 254.0| 209.0|20574.0|    1.0|     GU|20577.0|  71.0|    2.0|  1.0|20160430|      G|      O|      M| 1945.0|07292016|     F|     UA|5.9513706133E10|00178|      WT|    AGA|\n",
      "|5750215.0|2016.0|   4.0| 254.0| 209.0|20574.0|    1.0|     GU|20577.0|  65.0|    2.0|  1.0|20160430|      G|      O|      M| 1951.0|07292016|     F|     UA|5.9513649333E10|00178|      WT|    AGA|\n",
      "|5750216.0|2016.0|   4.0| 254.0| 209.0|20574.0|    1.0|     GU|20577.0|  65.0|    2.0|  1.0|20160430|      G|      O|      M| 1951.0|07292016|     M|     UA|5.9513623733E10|00178|      WT|    AGA|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+------+-------+-----+--------+-------+-------+-------+-------+--------+------+-------+---------------+-----+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+------------------+-----------------------------+----------+--------------+--------+---------+-------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|      City|       Country|Latitude|Longitude|i94port|\n",
      "+----------+------------------+-----------------------------+----------+--------------+--------+---------+-------+\n",
      "|2013-01-01|3.7110000000000003|                        0.649|Birmingham|United Kingdom|  52.24N|    2.63W|    BHX|\n",
      "|2013-02-01|             3.143|                        0.359|Birmingham|United Kingdom|  52.24N|    2.63W|    BHX|\n",
      "|2013-03-01|3.0730000000000004|                        0.469|Birmingham|United Kingdom|  52.24N|    2.63W|    BHX|\n",
      "|2013-04-01|7.1979999999999995|                        0.369|Birmingham|United Kingdom|  52.24N|    2.63W|    BHX|\n",
      "|2013-05-01|10.489999999999998|                        0.534|Birmingham|United Kingdom|  52.24N|    2.63W|    BHX|\n",
      "+----------+------------------+-----------------------------+----------+--------------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+--------------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+-------+\n",
      "|      City|               State|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|                Race| Count|i94port|\n",
      "+----------+--------------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+-------+\n",
      "|Washington|District of Columbia|      33.8|         319705|           352523|          672228|             25963|       95117|                  2.24|        DC|Black or African-...|328786|    WAS|\n",
      "|Washington|District of Columbia|      33.8|         319705|           352523|          672228|             25963|       95117|                  2.24|        DC|  Hispanic or Latino| 71129|    WAS|\n",
      "|Washington|District of Columbia|      33.8|         319705|           352523|          672228|             25963|       95117|                  2.24|        DC|American Indian a...|  6130|    WAS|\n",
      "|Washington|District of Columbia|      33.8|         319705|           352523|          672228|             25963|       95117|                  2.24|        DC|               Asian| 35072|    WAS|\n",
      "|Washington|District of Columbia|      33.8|         319705|           352523|          672228|             25963|       95117|                  2.24|        DC|               White|285402|    WAS|\n",
      "+----------+--------------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+--------------+--------------------+------------+---------+-----------+----------+--------------------+--------+----------+--------------------+---------+\n",
      "|ident|          type|                name|elevation_ft|continent|iso_country|iso_region|        municipality|gps_code|local_code|         coordinates|iata_code|\n",
      "+-----+--------------+--------------------+------------+---------+-----------+----------+--------------------+--------+----------+--------------------+---------+\n",
      "| KFHU|medium_airport|Sierra Vista Muni...|        4719|       NA|         US|     US-AZ|Fort Huachuca Sie...|    KFHU|       FHU|-110.344001770019...|      FHU|\n",
      "| PGUM| large_airport|Antonio B. Won Pa...|         298|       OC|         GU|    GU-U-A|HagÃ¥tÃ±a, Guam I...|    PGUM|       GUM|144.796005249, 13...|      GUM|\n",
      "| KAVP|medium_airport|Wilkes Barre Scra...|         962|       NA|         US|     US-PA|Wilkes-Barre/Scra...|    KAVP|       AVP|-75.7233963013000...|      AVP|\n",
      "| SWFX| small_airport|SÃ£o FÃ©lix do Ar...|         650|       SA|         BR|     BR-MT|SÃ£o FÃ©lix Do Ar...|    SWFX|      SWFX|-50.6896018981933...|      SXO|\n",
      "| SANE|medium_airport|Vicecomodoro Ange...|         656|       SA|         AR|      AR-G| Santiago del Estero|    SANE|       SDE|-64.3099975586, -...|      SDE|\n",
      "+-----+--------------+--------------------+------------+---------+-----------+----------+--------------------+--------+----------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# have a look at tables, if necessary\n",
    "parI94.show(n=5)\n",
    "parTemp.show(n=5)\n",
    "parDem.show(n=5)\n",
    "parAir.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Example Query**: find out, if cities with the most immigrants are indeed cities with the largest foreign-born counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Make sure that column `count` in `immigration` only contains `1` as entry so that columns `cicid` can be used to count total immigrants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|count|  count|\n",
      "+-----+-------+\n",
      "|  1.0|2306750|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parI94.select('count').groupby('count').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run Query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "example_query = spark.sql('''\n",
    "        SELECT city AS City, CAST(foreign_born AS INT) AS No_Foreign_Born, COUNT(cicid) AS No_Immigrants\n",
    "        FROM immigration JOIN demographics on (immigration.i94port = demographics.i94port)\n",
    "        GROUP BY City, No_Foreign_Born\n",
    "        ORDER BY (No_Immigrants, No_Foreign_Born) DESC\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-------------+\n",
      "|           City|No_Foreign_Born|No_Immigrants|\n",
      "+---------------+---------------+-------------+\n",
      "|       New York|        3212500|      1871590|\n",
      "|          Miami|         260789|      1386775|\n",
      "|    Los Angeles|        1485425|      1191015|\n",
      "|  San Francisco|         297199|       657900|\n",
      "|         Newark|          86253|       635170|\n",
      "|        Orlando|          50558|       582210|\n",
      "|        Chicago|         573463|       491460|\n",
      "|        Houston|         696210|       419280|\n",
      "|Fort Lauderdale|          47582|       382450|\n",
      "|      Las Vegas|         127609|       381630|\n",
      "|        Atlanta|          32016|       301930|\n",
      "|         Dallas|         326825|       242265|\n",
      "|         Boston|         190123|       203270|\n",
      "|        Seattle|         119840|       181595|\n",
      "|        Phoenix|         300702|       154250|\n",
      "|        Detroit|          39861|       120525|\n",
      "|   Philadelphia|         205339|       111780|\n",
      "|          Tampa|          58795|        88865|\n",
      "|      Charlotte|         128897|        71870|\n",
      "|         Denver|         113222|        64290|\n",
      "+---------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_query.show(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After retrieving the data from the query, it is saved as `pandas` dataframe and a correlation matrix is created, which shows a high correlation between the number of immigrants and the number of foreign-born citizens.\n",
    "\n",
    "\n",
    "This shows that cities with the most immigrants are indeed cities with the largest foreign-born counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 No_Foreign_Born  No_Immigrants\n",
      "No_Foreign_Born         1.000000       0.795511\n",
      "No_Immigrants           0.795511       1.000000\n"
     ]
    }
   ],
   "source": [
    "# write to pandas dataframe and create correlation matrix\n",
    "example_query_pd = example_query.toPandas()\n",
    "print(example_query_pd.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Dimension Tables:\n",
    "\n",
    "**Temperature:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| dt | Datetime stamp |\n",
    "| AverageTemperature | Avg Temp of city |\n",
    "| AverageTemperatureUncertainty | Uncertainty of Avg Temp of city|\n",
    "| City | City name |\n",
    "| Country | Country name |\n",
    "| Latitude | Latitude coordinates |\n",
    "| Longitude | Longitude coordinates|\n",
    "| i94port | Port of entry |\n",
    "\n",
    "**Demographics:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| City | City name |\n",
    "| State | State name|\n",
    "| Median Age | Average age of residents |\n",
    "| Male Population | Number of male residents |\n",
    "| Female Population | Number of female residents |\n",
    "| Total Population | Number of total residents |\n",
    "| Number of Veterans | Number of residents that are veterans |\n",
    "| Foreign-born | Number of residents not born in country |\n",
    "| Average Household Size | Average size of residents in single house |\n",
    "| State Code | Two letter state code |\n",
    "| Race | Most promemnant race in country |\n",
    "| Count | Count of largest race demographic |\n",
    "| i94port | Port of entry |\n",
    "\n",
    "**Airport Code:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| ident | Airport identity number |\n",
    "| type | Type of airport by size |\n",
    "| name | Airport name |\n",
    "| elevation_ft | Elevation of airport in feet |\n",
    "| continent | Continent of the airport |\n",
    "| iso_country | Country of airport |\n",
    "| iso_region | Region of airport within country |\n",
    "| municipality | Municipality of airport |\n",
    "| gps_code | GPS code |\n",
    "| iata_code | IATA code |\n",
    "| local_code | Local identity code |\n",
    "| coordinates | Latitude and Longitude of airport |\n",
    "\n",
    "\n",
    "### Fact Table:\n",
    "\n",
    "**Immigration:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---|---|\n",
    "| cicid | Record ID |\n",
    "| i94yr | 4 digit year|\n",
    "| i94mon | Month |\n",
    "| i94cit | Country of citizenship |\n",
    "| i94res | Country of residence |\n",
    "| i94port | Port of entry |\n",
    "| arrdate | Arrivate date |\n",
    "| i94mode | Mode of transportation |\n",
    "| i94addr | State of arrival in USA |\n",
    "| depdate | Departure date |\n",
    "| i94bir | Birth year of respondant |\n",
    "| i94visa | Visa type |\n",
    "| count | Summary statistics |\n",
    "| dtadfile | Date added to i94 files |\n",
    "| entdepa | Arrival flag |\n",
    "| entdepd | Departure flag |\n",
    "| matflag | Match flag |\n",
    "| biryear | Birth year |\n",
    "| dtaddto | Date admitted to USA |\n",
    "| gender | Gender of respondant |\n",
    "| airline | Airline of entry |\n",
    "| admnum | Admission number |\n",
    "| fltno | Flight number |\n",
    "| visatype | Type of visa held by repondant |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.1 Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Spark was chosen as technology as at least two of the data sets used contain more than one million rows and might receive updates daily. \n",
    "\n",
    "* The immigration data could even be used with streaming data which can be well handled by Spark. \n",
    "\n",
    "* In addition, Spark can deal with rapidly increasing amounts of data, e.g. in case of an international conflict that leads to a spike in immigration cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.2 Propose how often the data should be updated and why\n",
    "The fact table should be updated monthly, as new immigration is published monthly.\n",
    "The dimension tables should be updated less often, e.g. checked every month for inconsistencies or if they are out of date. If they are not up-to-date, they should be updated immediatly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3 Write a description of how you would approach the problem differently under the following scenarios:\n",
    " - **The data was increased by 100x:** To scale up Spark, the number of worker nodes can simply be increased to handle higher volumes of data\n",
    " - **The data populates a dashboard that must be updated on a daily basis by 7am every day:** \n",
    " If the prototype is accepted by the Use Case Owner, Apache Airflow can be used in the scaled-up version to run the ETL process as a scheduled DAG so that it finishes every day by 7am\n",
    " - **The database needed to be accessed by 100+ people**:\n",
    " If a database is needed, it could be migrated to AWS Redshift to allow auto-scaling to handle an increasing amount of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 6 Delete Output, if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%rm -rf ./output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
